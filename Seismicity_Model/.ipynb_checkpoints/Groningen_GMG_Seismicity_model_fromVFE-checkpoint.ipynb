{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d791c8c6",
   "metadata": {},
   "source": [
    "# Groningen Seismicity model\n",
    "This notebook allows running the seismicity model developped at GMG for gas extraction from the Groningen gas field following Smith et al., 2022, Heimisson et al., 2022, and Meyer et al.,2022.\n",
    "\n",
    "The most complete description of the model can be found in:\n",
    "\n",
    "Smith, J. D., Heimisson, E. R., Bourne, S. J., & Avouac, J. P. (2022). Stress-based forecasting of induced seismicity with instantaneous earthquake failure functions: applications to the Groningen Gas Reservoir. Earth and Planetary Science Letters, 594, 117697.\n",
    "\n",
    "---and---\n",
    "\n",
    "Heimisson, E. R., Smith, J. D., Avouac, J. P., & Bourne, S. J. (2022). Coulomb threshold rate-and-state model for fault reactivation: application to induced seismicity at Groningen. Geophysical Journal International, 228(3), 2061-2072.\n",
    "\n",
    "\n",
    "A full description of the needed libraries and tested practice on installation and running can be found in the file: Groningen_GMG_Seismicity_model_libraries.txt\n",
    "\n",
    "A description of the integration of this module with the rest of the modelling workflow can be found in the file:\n",
    "../README_GroningenModels_GMG.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15b8a4",
   "metadata": {},
   "source": [
    "## 1. Libraries and data set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239eac8",
   "metadata": {},
   "source": [
    "### 1.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca698ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided # to average arrays\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from math import *\n",
    "import pandas as pd \n",
    "from matplotlib.patches import Circle, Wedge, Polygon\n",
    "import scipy\n",
    "import theano.tensor as tt\n",
    "#the fancy axes\n",
    "import matplotlib.gridspec as gridspec\n",
    "# Gaussian Smoothing\n",
    "from astropy.convolution import Gaussian2DKernel\n",
    "from astropy.convolution import convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115e637",
   "metadata": {},
   "source": [
    "### 1.2. Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e3efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.Plotting_functions import cornerplot, rateplot\n",
    "from Functions.Failure_functions import *\n",
    "from Functions.Forecasting_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db3be4",
   "metadata": {},
   "source": [
    "## 2. MCMC inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ba112",
   "metadata": {},
   "source": [
    "### 2.1. Define the method to be used, and inference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87d65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the failure function to be used\n",
    "## TRS == Treshold Rate and State --> Heimisson et al., 2022\n",
    "## RS == Classic Rate and State --> Dieterich., 1994\n",
    "## ET == Extreme Threshold --> Bourne et al., 2017\n",
    "## GF == Gaussian Failure --> Smith et al., 2022\n",
    "Failure_function = 'TRS'\n",
    "LogLikelihood = 'Gaussian'\n",
    "\n",
    "if Failure_function =='TRS':\n",
    "    method = ThresholdRateAndState_logSampled()\n",
    "    labels = ['$r$ (evts/year)','$A \\sigma$ (MPa)','$\\Delta S_c$ (MPa)','$t_a$ (years)']\n",
    "    LLK = LogLikelihood # log likelihood\n",
    "    \n",
    "elif Failure_function =='RS':\n",
    "    method = ClassicRateAndState_logSampled() \n",
    "    labels = ['$r$ (evts/year)','$A \\sigma$ (MPa)','$t_a$ (years)']\n",
    "    LLK = LogLikelihood # log likelihood\n",
    "\n",
    "elif Failure_function =='ET':\n",
    "    method = ExtremeThreshold() \n",
    "    labels = ['$\\beta_0$','$\\beta_1$','$\\beta_2$']\n",
    "    LLK = LogLikelihood # log likelihood\n",
    "\n",
    "elif Failure_function =='GF':\n",
    "    method = GaussianFailure()\n",
    "    labels = ['$\\beta_0$','$\\beta_1$','$\\beta_2$']\n",
    "    LLK = LogLikelihood # log likelihood\n",
    "    \n",
    "# Define parameters for the inversions\n",
    "Num_samples = 5000 # samples for the MCMC inversion\n",
    "Warmup_percentage = 20 # percentage burn-in samples\n",
    "Num_chains = 10  #number of chains for the inversion\n",
    "Training = [1992,2016] # Training period\n",
    "Validation = [2016,2022] # Validation period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d437e5",
   "metadata": {},
   "source": [
    "### 2.2. Prepare the data for the MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888f161c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the Coulomb Stress data\n",
    "dC_raw = np.load('../Simulation_results/Mechanical_model/max_coulomb_stresses_resampled_mp.npy',allow_pickle=True)\n",
    "# Smooth it to 3km \n",
    "kernel = Gaussian2DKernel(6)\n",
    "dC = np.array([convolve(dC_raw[:,:,ii],kernel,nan_treatment='fill') for ii in range(dC_raw.shape[-1])]).transpose((1, 2, 0))\n",
    "#Load time\n",
    "tt=np.load('../Simulation_results/Reservoir_model/time_decimal_resampled_mp.npy',allow_pickle=True)\n",
    "\n",
    "# Average yearly\n",
    "dC_y ={} # Disctionnary to store the yearly data\n",
    "dC_y['Coulomb'] = np.nanmean(as_strided(dC, shape=(dC.shape[0], dC.shape[1], int(dC.shape[-1]/12), 12),strides=(dC.strides[0], dC.strides[1], dC.strides[2]*12, dC.strides[2])),axis=3)\n",
    "dC_y['Time']    = tt[0::12][:-1].round(0)\n",
    "\n",
    "# Load the seismicity catalog\n",
    "catalog_file = '../Inputs/Seismic_catalog/KNMI_CAT_1991-12to2023-01_InsideReservoir.csv'\n",
    "\n",
    "# Define the completion magnitude to use\n",
    "Mc =1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc6bf16",
   "metadata": {},
   "source": [
    "### 2.3. Run MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c821f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Training - Running MCMC =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiprocess sampling (10 chains in 4 jobs)\n",
      "CompoundStep\n",
      ">Metropolis: [θ4]\n",
      ">Metropolis: [θ3]\n",
      ">Metropolis: [θ2]\n",
      ">Metropolis: [θ1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='50000' class='' max='50000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [50000/50000 06:47&lt;00:00 Sampling 10 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 10 chains for 1_000 tune and 4_000 draw iterations (10_000 + 40_000 draws total) took 425 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Run the MCMC inversion\n",
    "# Create the forecasting object\n",
    "SF = SeismicityForecasting(method,catalog_file,dC_y,num_samples=Num_samples,warmup_percentage=Warmup_percentage,num_chains=Num_chains,Mc=Mc)# load the forecasting model and give the parameters)\n",
    "# Run the inference\n",
    "SF.run(training=Training,validation=Validation,LLK=LLK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e24af",
   "metadata": {},
   "source": [
    "## 3. Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3676c",
   "metadata": {},
   "source": [
    "### 3.1 The corner plots for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29068f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "File_cornerplot = None#f'Figures/cornerplot_method={method}.png'\n",
    "cornerplot(SF,File_cornerplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5f5ce",
   "metadata": {},
   "source": [
    "### 3.2. The rate plots for temporal evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b90c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "File_rateplot = None#f'Figures/rateplot_method={method}.png'\n",
    "rateplot(SF,File_rateplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = {} #dictionnary containing the seismicity\n",
    "ds['betas'] = SF.Training['betas']\n",
    "ds['Rpred'] = SF.FullModel['Rpred']\n",
    "ds['t_Rpred'] = SF.FullModel['Time']\n",
    "# --  logn : normalization of logp\n",
    "logn    = SF.Training['logp']-np.nanmin(SF.Training['logp'])\n",
    "logn    = logn/np.nanmax(logn)\n",
    "logpn   = 1 - logn\n",
    "idx     = np.argsort(logpn)[::-1] #argsort returns the indexes to sort the table\n",
    "ds['logp'] = SF.Training['logp']\n",
    "ds['logp_normalized'] = logpn\n",
    "# Observed catalog\n",
    "ds['Robs']   = SF.FullModel['Robs']\n",
    "ds['t_Robs'] = np.repeat(SF.Catalogue['Dates'],2)[1:]\n",
    "\n",
    "#Training and validation periods\n",
    "ds['Training'] = SF.training_period\n",
    "ds['Validation'] = SF.validation_period\n",
    "\n",
    "# Priors\n",
    "ds['Priors'] = [[a,b] for a,b in zip(SF.ForecastingModel.prior_min,SF.ForecastingModel.prior_max)]\n",
    "\n",
    "# Save the Forecast as is.\n",
    "np.save('../Simulation_results/Seismicity_Model/Seismicity_forecast_From_mp.npy',ds,allow_pickle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# track the date where this was run\n",
    "import dateime\n",
    "def update_run_date(file_path, model_name):\n",
    "  \"\"\"Updates the run date for a specific model in a text file.\n",
    "\n",
    "  Args:\n",
    "    file_path: The path to the text file.\n",
    "    model_name: The name of the model to update.\n",
    "  \"\"\"\n",
    "\n",
    "  now = datetime.datetime.now()\n",
    "  new_date = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "  lines = []\n",
    "  with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "      if model_name in line:\n",
    "        lines.append(f\"{model_name}: {new_date}\\n\")\n",
    "      else:\n",
    "        lines.append(line)\n",
    "\n",
    "  with open(file_path, 'w') as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "file_path = \"../../model_run_dates.txt\"\n",
    "update_run_date(file_path, \"Groningen Seismicity Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c0ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
